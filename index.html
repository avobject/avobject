<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Object-Aware Audio-Visual Sound Generation">
  <meta name="keywords" content="AVObject, Audio Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Object-Aware Audio-Visual Sound Generation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Object-Aware Audio-Visual Sound Generation</h1>

          <div class="is-size-5 publication-authors">

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser" style="margin-top: -30px;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <!-- First column in its own row -->
      <div class="column is-three-fifths">
        <h3 class="subtitle has-text-centered">
          <b>tl;dr:</b> We generate object-specific sounds in complex visual scenes using user-provided segmentation masks.
        </h3>
      </div>
    </div>
    <!-- Second column in a separate row -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="is-centered is-max-desktop teaser">
          <div>
            <!-- <video class="center-video" autoplay muted loop playsinline style="margin: 1em auto 0 auto;"> -->
              <!-- <source src="./static/videos/teaser.mp4" type="video/mp4"> -->
              <div style="text-align: center;">
              <img src="./static/images/teaser.jpg" alt="Teaser Image" style="width: 100%">
              <p style="text-align: left; margin-top: 1em;">
              <b>Object-aware sound generation.</b> We generate sound aligned with specific visual objects in complex scenes. Users can select objects in the scene using segmentation masks, and the model generates audio corresponding to the selected objects. Here, we show a busy street with multiple sound sources (left). After training, our model generates object-specific audio (right), such as crowd noise for people, engine sounds for cars, and ambient wind for the sky.
              </p>
    

            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating accurate sounds for complex audio-visual scenes is challenging, especially when multiple objects and sound sources are present. In this paper, we introduce an <i>object-aware sound generation</i> model that aligns generated sounds with visual objects in a scene. By grounding sound generation in object-centric representations, our model learns to associate specific visual objects with their corresponding sounds. We fine-tune a conditional latent diffusion model with dot-product attention to improve sound-object alignment. At test time, users can compositionally generate sounds by selecting objects via segmentation masks. We theoretically validate our test-time object-grounding ability, ensuring that even subtle sounds can be represented. Quantitative and qualitative evaluations show that our model outperforms baselines, achieving better alignment between objects and their associated sounds.          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Compositional Sound Generation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Compositional Sound Generation
        </h2>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/comp-1-preview.png">
            <source src="./static/videos/comp-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/comp-2-preview.png">
            <source src="./static/videos/comp-2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Compositional Sound Generation. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Sound Adaptation to Visual Texture Changes. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Sound Adaptation to Visual Texture Changes</h2>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/ada-1-preview.png">
            <source src="./static/videos/ada-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/ada-2-preview.png">
            <source src="./static/videos/ada-2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!-- Sound Adaptation to Visual Texture Changes. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Generation Results with In-Domain Examples. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Generation Results with In-Domain Examples</h2>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/indomain-1-preview.png">
            <source src="./static/videos/indomain-1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/indomain-2-preview.png">
            <source src="./static/videos/indomain-2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <video width=100% controls="controls" poster="./static/poster/indomain-3-preview.png">
            <source src="./static/videos/indomain-3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!-- Generation Results with In-Domain Examples. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Model Architecture. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Model Architecture</h2>
        <div class="content has-text-justified">
          <img src="./static/images/method.jpg">
          <p style="text-align: left; margin-top: 2em;">
            We encode the reference spectrogram via a pre-trained latent encoder. An image and text prompt are processed by separate encoders, and their embeddings are fused using an attention mechanism to highlight relevant objects. We then feed these conditioned features and noisy latent into a latent diffusion model to generate the object-specific audio. Finally, the latent decoder reconstructs the spectrogram, and a pre-trained HiFi-GAN vocoder generates the final audio waveform. At test time, we replace the attention with a user-provided segmentation mask, and the latent encoder for the reference spectrogram is <i>not</i> used. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Model. -->
  </div>
</section>







<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{park2021nerfies
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
      </div>
    </div>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a 
            <a rel="license" 
            href="http://creativecommons.org/licenses/by-sa/4.0/"
            target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>, 
            and is written by <a href="https://keunhong.com/" target="_blank">
            Keunhong Park</a> for the <a href="https://nerfies.github.io/" 
            target="_blank">Nerfies</a> project. Feel free to use the 
            <a href="https://github.com/nerfies/nerfies.github.io"
            target="_blank">source code</a> of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script type="text/javascript"> 
var sc_project=12691142;  
var sc_invisible=1;  
var sc_security="b5064dc1";  
</script> 
<script type="text/javascript" 
src="https://www.statcounter.com/counter/counter.js" 
async></script> 
<noscript><div class="statcounter"><a title="Web Analytics" 
href="https://statcounter.com/" target="_blank"><img 
class="statcounter" 
src="https://c.statcounter.com/12691142/0/b5064dc1/1/" 
alt="Web Analytics" 
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript> 
  
</body>
</html>
